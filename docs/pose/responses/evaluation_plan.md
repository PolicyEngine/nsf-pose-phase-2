## Evaluation Plan

### Key Performance Indicators

**Ecosystem Growth**:
- User adoption: Monthly active users, new registrations, retention rates
- Geographic reach: States and countries with active users
- Institutional adoption: Government agencies, universities, nonprofits using platform
- Community contributions: Pull requests, issues filed, documentation improvements

**Impact Metrics**:
- Policy analyses: Number and quality of published analyses using PolicyEngine
- Benefits accessed: Dollar value of benefits identified through partner organizations
- Students trained: Course enrollments, certifications issued, career placements
- Research output: Academic papers citing PolicyEngine, methodological advances

**Technical Health**:
- System reliability: API uptime, response times, error rates
- Code quality: Test coverage, bug resolution time, release frequency
- Validation accuracy: Agreement rates with established models (TAXSIM, CBO, TPC)
- Security posture: Vulnerability scan results, time to patch, dependency updates

### Data Collection Methods

**Automated tracking**: Platform analytics for usage patterns, API calls, user segments
**Surveys**: Quarterly user satisfaction, annual community health assessment
**Case studies**: Deep dives on high-impact use cases (state legislation, research breakthroughs)
**External validation**: Independent audits of calculations, security reviews

### Evaluation Timeline

**Monthly**: Usage metrics dashboard, bug tracking, release notes
**Quarterly**: User surveys, financial reports, community meeting
**Annually**: Impact assessment, sustainability review, strategic planning

### Advisory Board Review

External advisors from NBER, Georgetown, USC, and government partners will conduct annual reviews assessing:
- Progress against milestones
- Community health indicators
- Financial sustainability trajectory
- Strategic direction alignment

Results will be published transparently, informing course corrections and demonstrating accountability to funders and users.