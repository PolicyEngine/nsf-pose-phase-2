We will grow external contributors and maintainers, increase deployments across academic, civic, and policy organizations, and improve issue and review throughput as well as release cadence. The January I‑Corps for POSE cohort anchors our discovery work: we will conduct roughly one hundred structured interviews across policy analysts, researchers, journalists, civic‑tech developers, and state and local staff, synthesize the adoption blockers we hear, and translate those findings into a public roadmap that unblocks real users. We include a design‑freeze milestone in the first quarter to incorporate I‑Corps outcomes before the broader rollout. In parallel, we will cultivate pilot adopters and contributor pipelines with research partners such as NBER‑affiliated teams and universities including Georgetown and USC, along with think tanks and civic‑tech groups.

Contributor onboarding will feel purposeful and supportive. We will publish starter issues and step‑by‑step contributor guides, pair new contributors with maintainers, and hold regular office hours. Quarterly workshops and hackathons will bring users and maintainers together, and we will add fellowship opportunities where appropriate. For users, we will ship complete examples and datasets and provide “one‑command” analyses so the first run succeeds; releases will be accompanied by migration notes and clear change summaries.

Where it helps adoption, we will engage industry and international collaborators for use‑cases and contributions under compatible licenses, making our contributor and licensing guidance explicit from the outset. Over the first year, we expect to complete interviews and publish the adoption‑blockers report and onboarding materials; establish baseline security practices including SBOM and signed releases; ship high‑value data adapters; and complete at least two pilots. By the end of the first year we intend to have community maintainers operating in at least two domains and several case studies documenting impact and performance improvements.

### Commercial Adoption Channels
PolicyEngine’s OSE is strengthened by commercial users whose day‑to‑day needs closely overlap with public‑interest analysis. Tax accountants and tax‑software vendors can use the rules engine to test scenarios and ensure compliance across federal and state regimes; when they request a new provision or fix, our contribution playbook makes it easy to upstream the change—either by submitting a pull request themselves or by funding us or a maintainer to implement it with tests and documentation so it benefits the wider policy community. Market‑research organizations and retailers can use our calibrated local microdata (with forthcoming consumption integration) to understand county‑level demand, affordability, and incidence under policy changes; their improvements to data adapters, validation, or pipelines are likewise upstreamed and versioned. Financial institutions can apply the same local datasets and rules for economic projections and stress‑testing; where they underwrite performance improvements, we turn them into documented, reproducible releases. In each case, a permissive license, clear governance, and a straightforward CLA/DCO path align commercial incentives with public benefit.

Two concrete integrations illustrate immediate momentum. First, the UK Cabinet Office engagement is already informing government‑grade workflows; we will capture the lessons into governance and adoption playbooks and seek a formal letter of collaboration. Second, we will develop calibrated weights for states and congressional districts and package them as reusable data artifacts with documented pipelines, supported by Arnold Ventures in the U.S. following earlier UK work funded by the Nuffield Foundation. Alongside these, we will publish stable releases of L0, MicroImpute, and MicroCalibrate with quickstarts and examples and invite maintainers to steward each module.

We will track progress using a small set of meaningful indicators: non‑team pull requests and issues per month, active maintainers and time‑to‑review, release frequency and the number of named deployments, and the reproducibility of published analyses. These measures are simple to compute and make adoption and contributor health visible to reviewers and partners.

### Current Users and Collaborators
PolicyEngine already supports real policy workflows. The U.S. Joint Economic Committee has used the platform to examine distributional and budget questions. New York State Senator Andrew Gounardes’s office and D.C. Councilmember Zachary Parker’s office have both used the rules engine to simulate tax‑credit reform proposals, iterating quickly on design details and distributional effects. The Niskanen Center uses PolicyEngine for public‑interest policy analysis and communication. The New York Times also employed the model during its coverage of the 2025 reconciliation bill (the “One Big Beautiful Bill Act”), and although that analysis was not published due to the bill passing more quickly than expected, that work hardened our release and validation processes. With support from the Nuffield Foundation, we enlisted Citizen Codex to conduct a UX research study; the findings are informing contributor onboarding, documentation structure, and the layout of example‑driven “first‑run” experiences.
